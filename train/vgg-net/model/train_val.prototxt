name: "VGGFCNNet"

layer {
  name: "data"
  type: "DataHeatmap"
  top: "data"
  top: "label"
  visualise: false
  include: { phase: TRAIN }
  heatmap_data_param {
    //todo source: "/data/tp/flic/train_shuffle.txt"
    //todo root_img_dir: "/mnt/ramdisk/tp/flic/"
    batchsize: 14
    cropsize: 198
    outsize: 256
    sample_per_cluster: false
    random_crop: true
    label_width: 64
    label_height: 64
    segmentation: false
    flip_joint_labels: true
    dont_flip_first: true
    angle_max: 40
    multfact: 1  # set to 282 if using preprocessed data from website
  }
}
layer {
  name: "data"
  type: "DataHeatmap"
  top: "data"
  top: "label"
  visualise: false
  include: { phase: TEST }
  heatmap_data_param {
    //todo source: "/data/tp/flic/test_shuffle.txt"
    //todo root_img_dir: "/mnt/ramdisk/tp/flic/"
    batchsize: 1
    cropsize: 198
    outsize: 256
    sample_per_cluster: false
    random_crop: false
    label_width: 64
    label_height: 64
    segmentation: false
    dont_flip_first: true
    angle_max: 0
    multfact: 1  # set to 282 if using preprocessed data from website
  }
}

#############################################################################################
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}

layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}

layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

#############################################################################################
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}

layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}

layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

#############################################################################################
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

#############################################################################################
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}

layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}

layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

#############################################################################################
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}

layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}

layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}

layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}

#############################################################################################
layers {
  bottom: "pool5"
  top: "conv6"
  name: "conv6"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 4096
    kernel_size: 7
  }
}
layers {
  bottom: "conv6"
  top: "conv6"
  name: "relu6"
  type: RELU
}

#############################################################################################
layers {
  bottom: "conv6"
  top: "conv7"
  name: "conv7"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 4096
    kernel_size: 1
  }
}
layers {
  bottom: "conv7"
  top: "conv7"
  name: "relu7"
  type: RELU
}

#############################################################################################
layers {
  bottom: "conv7"
  top: "conv8"
  name: "conv8"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 13
    kernel_size: 1
  }
}
layers {
  bottom: "conv8"
  top: "conv8"
  name: "relu8"
  type: RELU
}


#############################################################################################
layer {
  name: "loss_fusion"
  type: "EuclideanLossHeatmap"
  bottom: "conv8"
  bottom: "label"
  bottom: "data"
  top: "loss_fusion"
  visualise: false
  loss_weight: 3
}